{"cells":[{"cell_type":"markdown","metadata":{"id":"bb31PGp6RI6J"},"source":["# **Grounded SAM2 for building part recognition**"]},{"cell_type":"markdown","metadata":{"id":"Zz5GygUoeQ5I"},"source":["A notebook for using Grounded SAM2 to export the segmentation of windows on a batched building file.\n","\n","https://github.com/autodistill/autodistill-grounded-sam-2"]},{"cell_type":"markdown","metadata":{"id":"kPm1iERe8QIp"},"source":["## **Preparation**"]},{"cell_type":"markdown","metadata":{"id":"AFTj0jN1DiCq"},"source":["CUDA version check for correct torch installation"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156,"status":"ok","timestamp":1757872507080,"user":{"displayName":"Lika","userId":"03593465285695465067"},"user_tz":-240},"id":"yEuB-ZtODd9d","outputId":"82c9644c-497a-4ed0-99c1-4516cc50e78c"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2024 NVIDIA Corporation\n","Built on Thu_Jun__6_02:18:23_PDT_2024\n","Cuda compilation tools, release 12.5, V12.5.82\n","Build cuda_12.5.r12.5/compiler.34385749_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"markdown","metadata":{"id":"ovdYYrse8b0y"},"source":["Works only when I use torch version for CUDA 12.1\n","It might need to be restarted to work properly once loaded"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_74eIB-8XEG","executionInfo":{"status":"ok","timestamp":1757872663111,"user_tz":-240,"elapsed":156027,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"5655f261-b519-4123-9059-81deffb92ace"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: torch 2.8.0+cu126\n","Uninstalling torch-2.8.0+cu126:\n","  Successfully uninstalled torch-2.8.0+cu126\n","Found existing installation: torchvision 0.23.0+cu126\n","Uninstalling torchvision-0.23.0+cu126:\n","  Successfully uninstalled torchvision-0.23.0+cu126\n","Found existing installation: torchaudio 2.8.0+cu126\n","Uninstalling torchaudio-2.8.0+cu126:\n","  Successfully uninstalled torchaudio-2.8.0+cu126\n","Looking in indexes: https://download.pytorch.org/whl/cu121\n","Collecting torch==2.5.1\n","  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.20.1\n","  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==2.5.1\n","  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (4.15.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m126.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m142.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (75.2.0)\n","Collecting sympy==1.13.1 (from torch==2.5.1)\n","  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m124.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1) (11.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n","Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.4.0\n","    Uninstalling triton-3.4.0:\n","      Successfully uninstalled triton-3.4.0\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.3\n","    Uninstalling sympy-1.13.3:\n","      Successfully uninstalled sympy-1.13.3\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.6.77\n","    Uninstalling nvidia-nvtx-cu12-12.6.77:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.27.3\n","    Uninstalling nvidia-nccl-cu12-2.27.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n","    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"]}],"source":["# uninstall previously installed version if needed\n","!pip uninstall torch torchvision torchaudio -y\n","\n","# # install PyTorch for CUDA 11.8\n","# !pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118\n","\n","# # install PyTorch for CUDA 12.1\n","!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu121"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYaa_2c5WhjQ","executionInfo":{"status":"ok","timestamp":1757872663805,"user_tz":-240,"elapsed":684,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"0fff1556-c145-4bc4-b135-e044535d6e62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'autodistill-grounded-sam-2'...\n","remote: Enumerating objects: 98, done.\u001b[K\n","remote: Counting objects: 100% (22/22), done.\u001b[K\n","remote: Compressing objects: 100% (8/8), done.\u001b[K\n","remote: Total 98 (delta 17), reused 14 (delta 14), pack-reused 76 (from 1)\u001b[K\n","Receiving objects: 100% (98/98), 24.97 KiB | 1.31 MiB/s, done.\n","Resolving deltas: 100% (45/45), done.\n"]}],"source":["!git clone https://github.com/autodistill/autodistill-grounded-sam-2.git"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8urp4myYWGEO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757872700107,"user_tz":-240,"elapsed":36299,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"e7b2ab77-e842-4aee-df27-8df656c584fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/autodistill-grounded-sam-2\n","Obtaining file:///content/autodistill-grounded-sam-2\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from autodistill_grounded_sam_2==0.1.0) (2.5.1+cu121)\n","Collecting autodistill (from autodistill_grounded_sam_2==0.1.0)\n","  Downloading autodistill-0.1.29-py3-none-any.whl.metadata (32 kB)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from autodistill_grounded_sam_2==0.1.0) (2.0.2)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from autodistill_grounded_sam_2==0.1.0) (4.12.0.88)\n","Collecting supervision (from autodistill_grounded_sam_2==0.1.0)\n","  Downloading supervision-0.26.1-py3-none-any.whl.metadata (13 kB)\n","Collecting roboflow (from autodistill_grounded_sam_2==0.1.0)\n","  Downloading roboflow-1.2.9-py3-none-any.whl.metadata (9.7 kB)\n","Collecting autodistill_florence_2 (from autodistill_grounded_sam_2==0.1.0)\n","  Downloading autodistill_florence_2-0.1.1-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from autodistill->autodistill_grounded_sam_2==0.1.0) (4.67.1)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from autodistill->autodistill_grounded_sam_2==0.1.0) (11.3.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from autodistill->autodistill_grounded_sam_2==0.1.0) (6.0.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from autodistill->autodistill_grounded_sam_2==0.1.0) (8.2.1)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (4.56.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (0.8.1)\n","Collecting flash-attn (from autodistill_florence_2->autodistill_grounded_sam_2==0.1.0)\n","  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (1.0.19)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (0.17.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (2025.8.3)\n","Collecting idna==3.7 (from roboflow->autodistill_grounded_sam_2==0.1.0)\n","  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (0.12.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (1.4.9)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (3.10.0)\n","Collecting opencv-python-headless==4.10.0.84 (from roboflow->autodistill_grounded_sam_2==0.1.0)\n","  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Collecting pi-heif<2 (from roboflow->autodistill_grounded_sam_2==0.1.0)\n","  Downloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n","Collecting pillow-avif-plugin<2 (from roboflow->autodistill_grounded_sam_2==0.1.0)\n","  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (2.9.0.post0)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (1.1.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (2.32.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (1.17.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (2.5.0)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow->autodistill_grounded_sam_2==0.1.0) (1.0.0)\n","Collecting filetype (from roboflow->autodistill_grounded_sam_2==0.1.0)\n","  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from supervision->autodistill_grounded_sam_2==0.1.0) (1.16.1)\n","Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision->autodistill_grounded_sam_2==0.1.0) (0.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (4.15.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (3.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (75.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch->autodistill_grounded_sam_2==0.1.0) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->autodistill_grounded_sam_2==0.1.0) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch->autodistill_grounded_sam_2==0.1.0) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow->autodistill_grounded_sam_2==0.1.0) (1.3.3)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow->autodistill_grounded_sam_2==0.1.0) (4.59.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow->autodistill_grounded_sam_2==0.1.0) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow->autodistill_grounded_sam_2==0.1.0) (3.2.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow->autodistill_grounded_sam_2==0.1.0) (3.4.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->autodistill_grounded_sam_2==0.1.0) (3.0.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (5.9.5)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft->autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (1.10.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft->autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (0.6.2)\n","Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft->autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (0.34.4)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm->autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (0.20.1+cu121)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (0.22.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft->autodistill_florence_2->autodistill_grounded_sam_2==0.1.0) (1.1.9)\n","Downloading autodistill-0.1.29-py3-none-any.whl (32 kB)\n","Downloading autodistill_florence_2-0.1.1-py3-none-any.whl (5.9 kB)\n","Downloading roboflow-1.2.9-py3-none-any.whl (88 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading supervision-0.26.1-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n","Building wheels for collected packages: flash-attn\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp312-cp312-linux_x86_64.whl size=255984554 sha256=51f6422861ed951b968428adc9fa7406027f73f2145be5e163810df6f459abea\n","  Stored in directory: /root/.cache/pip/wheels/3d/59/46/f282c12c73dd4bb3c2e3fe199f1a0d0f8cec06df0cccfeee27\n","Successfully built flash-attn\n","Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, supervision, roboflow, flash-attn, autodistill, autodistill_florence_2, autodistill_grounded_sam_2\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.12.0.88\n","    Uninstalling opencv-python-headless-4.12.0.88:\n","      Successfully uninstalled opencv-python-headless-4.12.0.88\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.10\n","    Uninstalling idna-3.10:\n","      Successfully uninstalled idna-3.10\n","  Running setup.py develop for autodistill_grounded_sam_2\n","Successfully installed autodistill-0.1.29 autodistill_florence_2-0.1.1 autodistill_grounded_sam_2-0.1.0 filetype-1.2.0 flash-attn-2.8.3 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.0 pillow-avif-plugin-1.5.2 roboflow-1.2.9 supervision-0.26.1\n","/content\n"]}],"source":["%cd autodistill-grounded-sam-2\n","!pip install --no-build-isolation -e .\n","%cd .."]},{"cell_type":"markdown","metadata":{"id":"SWIx0qvG8nU-"},"source":["Checking torch and cuda version"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"vu4p-EFf8t9a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757872701752,"user_tz":-240,"elapsed":1641,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"08c27a82-ba8d-4c8f-a0cb-d9a588aaeaa2"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.5.1+cu121 True\n","12.1\n"]}],"source":["import torch\n","print(torch.__version__, torch.cuda.is_available())\n","print(torch.version.cuda)"]},{"cell_type":"markdown","metadata":{"id":"XrstC1QSaLt7"},"source":["Checking if autodistill-grounded-sam-2 is installed"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"TE95pIWkUiWC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757872703407,"user_tz":-240,"elapsed":1653,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"f4e17b99-23a7-4ea5-d221-db040a7903bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Name: autodistill_grounded_sam_2\n","Version: 0.1.0\n","Summary: Use Segment Anything 2, grounded with Florence-2, to auto-label data for use in training vision models.\n","Home-page: https://github.com/autodistill/autodistill-grounded-sam-2\n","Author: Roboflow\n","Author-email: autodistill@roboflow.com\n","License: \n","Location: /content/autodistill-grounded-sam-2\n","Editable project location: /content/autodistill-grounded-sam-2\n","Requires: autodistill, autodistill_florence_2, numpy, opencv-python, roboflow, supervision, torch\n","Required-by: \n"]}],"source":["!pip show autodistill-grounded-sam-2"]},{"cell_type":"markdown","metadata":{"id":"bQ8W8YIARUYY"},"source":["---\n","##**Installing grounded SAM2**\n","\n","Cloning the git and installing the dependecies"]},{"cell_type":"markdown","metadata":{"id":"l5gRaM8rFboK"},"source":["***Grounded-SAM object detection model with the AutoDistill framework***"]},{"cell_type":"markdown","metadata":{"id":"YB4_Du0IFyBX"},"source":["rf_groundingdino is a dependency related to GroundingDINO, a model for referring expression object detection (i.e., detecting objects from natural language)."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"qK4EeNvdO2iH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757872712113,"user_tz":-240,"elapsed":8704,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"92ceea6e-ba11-4ab8-fb35-9c23545fd76c"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for autodistill_grounded_sam_2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install git+https://github.com/autodistill/autodistill-grounded-sam-2 rf_groundingdino -q"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"lcDcAD8oQdAl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757872726085,"user_tz":-240,"elapsed":13969,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"6655e587-39d6-4771-cb7e-3959b2eb9ffd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.49\n","  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.49) (3.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.49) (0.34.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.49) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.49) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.49) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.49) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.49) (2.32.4)\n","Collecting tokenizers<0.22,>=0.21 (from transformers==4.49)\n","  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.49) (0.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.49) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49) (2025.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49) (4.15.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49) (1.1.9)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.49) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.49) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.49) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.49) (2025.8.3)\n","Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.0\n","    Uninstalling tokenizers-0.22.0:\n","      Successfully uninstalled tokenizers-0.22.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.56.1\n","    Uninstalling transformers-4.56.1:\n","      Successfully uninstalled transformers-4.56.1\n","Successfully installed tokenizers-0.21.4 transformers-4.49.0\n"]}],"source":["!pip install transformers==4.49"]},{"cell_type":"code","source":["!pip install -q svgpathtools gradio"],"metadata":{"id":"q81EgJBiEC8a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757872731365,"user_tz":-240,"elapsed":5277,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"f1f0c703-d9dc-4ee9-8aea-3f8ebce8b580"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","metadata":{"id":"2t3b7axeewpI"},"source":["---\n","## **Importing the packages and testing SAM2**"]},{"cell_type":"markdown","metadata":{"id":"Snr73K_TQlJP"},"source":["it takes some time to load... like 4 min in A100"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4PgXwMgPQKop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757872982864,"user_tz":-240,"elapsed":251493,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"e40923ab-85ef-4cf7-ba97-dd374094814a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Importing from timm.models.layers is deprecated, please import via timm.layers\n"]},{"output_type":"stream","name":"stdout","text":["GroundedSAM2 is loaded successfully\n"]}],"source":["from autodistill_grounded_sam_2 import GroundedSAM2\n","print('GroundedSAM2 is loaded successfully')"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"bKq01QzbQP2g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757872982906,"user_tz":-240,"elapsed":47,"user":{"displayName":"Lika","userId":"03593465285695465067"}},"outputId":"c5d29d87-7e5b-4e31-ed03-e7c39783200e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Import is fine!\n"]}],"source":["from autodistill.detection import CaptionOntology\n","from autodistill.utils import plot\n","import numpy as np\n","import cv2\n","import os\n","import random\n","import supervision as sv\n","\n","print('Import is fine!')"]},{"cell_type":"markdown","metadata":{"id":"KlJLSp1zju25"},"source":["# **Gradio App**"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3kWB6pqhBtU3","colab":{"base_uri":"https://localhost:8080/","height":721},"outputId":"49cbe2b4-7c5a-4566-dd0b-130fb5d31311","executionInfo":{"status":"ok","timestamp":1757873501127,"user_tz":-240,"elapsed":166679,"user":{"displayName":"Lika","userId":"03593465285695465067"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["* Running on public URL: https://911de03825aac8ec2a.gradio.live\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://911de03825aac8ec2a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["trying to load grounding dino directly\n","final text_encoder_type: bert-base-uncased\n"]},{"output_type":"stream","name":"stderr","text":["You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","The `device` argument is deprecated and will be removed in v5 of Transformers.\n","torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","None of the inputs have requires_grad=True. Gradients will be None\n","`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n"]},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://911de03825aac8ec2a.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":14}],"source":["\n","\"\"\"\n","Architectural Facade Understanding (GroundedSAM2)\n","Segment, vectorize, and classify facade elements (incl. arches, circles, ellipses & wavy shapes).\n","\"\"\"\n","\n","import os\n","import cv2\n","import json\n","import zipfile\n","import logging\n","import tempfile\n","import numpy as np\n","import pandas as pd\n","import gradio as gr\n","from datetime import datetime\n","from dataclasses import dataclass\n","\n","# -----------------------------------------------------------------------------\n","# Logging & torch quiet mode\n","# -----------------------------------------------------------------------------\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","try:\n","    import torch\n","    torch.set_grad_enabled(False)\n","except Exception:\n","    pass\n","\n","# -----------------------------------------------------------------------------\n","# Globals\n","# -----------------------------------------------------------------------------\n","base_model = None\n","LAST_ONTOLOGY_SIG = None  # auto-reinit if user changes prompt\n","\n","\n","@dataclass\n","class Config:\n","    APP_TITLE = \"Architectural Facade Understanding (GroundedSAM2)\"\n","    APP_DESC = \"\"\"\n","# 🏛️ Architectural Facade Understanding\n","\n","A complete workflow to **detect**, **segment**, **vectorize**, and **classify** facade elements using GroundedSAM2 and geometry:\n","\n","**What it does**\n","- 🎯 Prompt-driven detection & segmentation (GroundingDINO + SAM2 via autodistill)\n","- 🧼 Smooth **SVG** conversion of masks (preserves curves/arches)\n","- 🧠 Geometry-aware classification: **circle**, **ellipse**, **rectangle**, polygons (triangle…hexagon…n-gon), **arched_shape**, and **wavy_shape**\n","- 🗂️ Professional outputs: **SVG**, **CSV**, **JSON**, **JPG**, consolidated **ZIP**\n","\n","**Roundness logic**\n","- Circles are proven with multiple tests (circularity, aspect ratio, radius std, Hausdorff, min-enclosing-circle residuals) with a Hough fallback for small blobs.\n","- Ellipses are detected via direct ellipse fit + residual checks.\n","\"\"\"\n","    DEFAULT_BOX_THRESHOLD = 0.02\n","    DEFAULT_TEXT_THRESHOLD = 0.02\n","    DEFAULT_CONF_THRESHOLD = 0.30\n","    DEFAULT_MAX_INCLUSIONS = 2\n","\n","    # Rectangle acceptance\n","    RECTANGLE_AREA_RATIO = 0.80\n","    RECTANGLE_HD_THRESHOLD = 8.0\n","    RECT_ORTHO_TOL_DEG = 12  # edges near 90°\n","\n","    # Circle thresholds (for medium+ shapes)\n","    CIRCULARITY_MIN = 0.90             # 4πA/P^2\n","    ELLIPSE_AR_MAX = 1.06              # circle ~= ellipse AR <= 1.06\n","    R_STD_FRAC_MAX = 0.08              # std(radius)/max(w,h)\n","    CIRC_HAUSDORFF_MAX = 6.5\n","    MEC_RES_FRAC_MAX = 0.08            # mean(|d-R|)/R\n","\n","    # Small-shape relaxed thresholds (scale = max(w,h) < SMALL_SHAPE_PX)\n","    SMALL_SHAPE_PX = 80\n","    CIRCULARITY_MIN_SMALL = 0.86\n","    ELLIPSE_AR_MAX_SMALL = 1.12\n","    R_STD_FRAC_MAX_SMALL = 0.12\n","    CIRC_HAUSDORFF_MAX_SMALL = 8.5\n","    MEC_RES_FRAC_MAX_SMALL = 0.12\n","\n","    # Ellipse thresholds (non-circular)\n","    ELLIPSE_MIN_AR = 1.08               # must be more elongated than a circle\n","    ELLIPSE_MAX_AR = 3.50\n","    ELLIPSE_RESIDUAL_FRAC_MAX = 0.14    # avg point-to-ellipse distance / max(rx,ry)\n","\n","    # Wavy shape heuristics\n","    WAVY_MIN_INFLECTIONS = 6\n","    WAVY_PERIM_TO_HULL_MIN = 1.18\n","    WAVY_AREA_HULL_RATIO_MIN = 0.85\n","\n","    # --- NEW: Arch guards / tuning to reduce rectangle mislabels ---\n","    ARCH_RECT_GUARD_AREA_RATIO = 0.93     # if rectangle fit is this good...\n","    ARCH_RECT_GUARD_HD = 3.0              # ...and close in Hausdorff, don't call it an arch\n","    ARCH_BASE_COVERAGE_MIN = 0.70         # flat base must span >= 70% of width\n","    ARCH_MIN_ARC_SPAN_DEG = 150           # top arc must span at least 150°\n","    ARCH_CIRCLE_INLIER_MIN_FRAC = 0.45    # >=45% of top points on the arc\n","\n","    PLOT_DPI = 150\n","    PLOT_FIGSIZE = (10, 10)\n","\n","\n","# -----------------------------------------------------------------------------\n","# Small utilities\n","# -----------------------------------------------------------------------------\n","def _to_list(x):\n","    if x is None:\n","        return []\n","    try:\n","        return list(np.array(x).tolist())\n","    except Exception:\n","        try:\n","            return list(x)\n","        except Exception:\n","            return []\n","\n","\n","def get_bounding_boxes(results):\n","    bbs = []\n","    xyxy = getattr(results, \"xyxy\", None)\n","    if xyxy is None and hasattr(results, \"boxes\"):\n","        xyxy = getattr(getattr(results, \"boxes\", None), \"xyxy\", None)\n","    if xyxy is None and isinstance(results, (list, tuple, np.ndarray)):\n","        xyxy = results\n","    if xyxy is None:\n","        return bbs\n","    xyxy = np.array(xyxy)\n","    if xyxy.ndim == 2 and xyxy.shape[1] >= 4:\n","        for x1, y1, x2, y2, *_ in xyxy:\n","            bbs.append([int(x1), int(y1), int(x2), int(y2)])\n","    else:\n","        for item in xyxy:\n","            if len(item) >= 4:\n","                x1, y1, x2, y2 = item[:4]\n","                bbs.append([int(x1), int(y1), int(x2), int(y2)])\n","    return bbs\n","\n","\n","def create_inclusion_mask(bounding_boxes, max_inclusions=3):\n","    n = len(bounding_boxes)\n","    mask = [False] * n\n","    for i in range(n):\n","        incl = 0\n","        x1_i, y1_i, x2_i, y2_i = bounding_boxes[i]\n","        for j in range(n):\n","            if i == j:\n","                continue\n","            x1_j, y1_j, x2_j, y2_j = bounding_boxes[j]\n","            if x1_i <= x1_j and y1_i <= y1_j and x2_i >= x2_j and y2_i >= y2_j:\n","                incl += 1\n","                if incl > max_inclusions:\n","                    mask[i] = True\n","                    break\n","    return mask\n","\n","\n","def _ensure_dir(p):\n","    os.makedirs(p, exist_ok=True)\n","    return p\n","\n","\n","def _parse_prompt_to_ontology_dict(prompt_text: str):\n","    if not prompt_text or not prompt_text.strip():\n","        return None\n","    pairs = []\n","    for chunk in [c.strip() for c in prompt_text.split(\",\") if c.strip()]:\n","        if \"->\" in chunk:\n","            cap, label = [t.strip() for t in chunk.split(\"->\", 1)]\n","        elif \":\" in chunk:\n","            cap, label = [t.strip() for t in chunk.split(\":\", 1)]\n","        else:\n","            cap = label = chunk.strip()\n","        if cap and label:\n","            pairs.append((cap, label))\n","    if not pairs:\n","        return None\n","    return {cap: label for cap, label in pairs}\n","\n","\n","# -----------------------------------------------------------------------------\n","# SVG from mask (dense contours to preserve curvature)\n","# -----------------------------------------------------------------------------\n","def _mask_to_svg_string(mask_uint8: np.ndarray) -> str:\n","    \"\"\"\n","    Convert a binary mask (0/255) to SVG by tracing contours.\n","    CHAIN_APPROX_NONE + light blur → smoother curves for arches/circles.\n","    \"\"\"\n","    m = mask_uint8.astype(np.uint8)\n","    if m.max() > 1:\n","        m = (m > 0).astype(np.uint8) * 255\n","    m = cv2.GaussianBlur(m, (5, 5), 0)\n","    _, m = cv2.threshold(m, 127, 255, cv2.THRESH_BINARY)\n","\n","    contours, _ = cv2.findContours(m, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    h, w = m.shape[:2]\n","\n","    try:\n","        import svgwrite\n","        dwg = svgwrite.Drawing(size=(w, h))\n","        dwg.viewbox(0, 0, w, h)\n","\n","        def contour_to_path(contour):\n","            if len(contour) == 0:\n","                return \"\"\n","            pts = [f\"{pt[0][0]},{pt[0][1]}\" for pt in contour]\n","            return \"M \" + \" L \".join(pts) + \" Z\"\n","\n","        for contour in contours:\n","            d = contour_to_path(contour)\n","            if d:\n","                dwg.add(dwg.path(d=d, fill='black', stroke='none'))\n","        return dwg.tostring()\n","    except Exception:\n","        elems = []\n","        for c in contours:\n","            pts = [f\"{pt[0][0]},{pt[0][1]}\" for pt in c]\n","            if not pts:\n","                continue\n","            d = \"M \" + \" L \".join(pts) + \" Z\"\n","            elems.append(f'<path d=\"{d}\" fill=\"black\" stroke=\"none\" />')\n","        return f'<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"{w}\" height=\"{h}\" viewBox=\"0 0 {w} {h}\">{\"\".join(elems)}</svg>'\n","\n","\n","# -----------------------------------------------------------------------------\n","# Classification (rectangle → arch → circle → ellipse → polygon → wavy)\n","# -----------------------------------------------------------------------------\n","def _classify_svg_assets(svg_file: str, out_dir: str):\n","    \"\"\"\n","    Classify shapes from SVG and produce:\n","      - classified_output.jpg (labeled preview)\n","      - classified_output.svg (clean, typed SVG with id/class attrs)\n","    Detects: circle, ellipse, rectangle, polygons (triangle…dodecagon…N), 'arched_shape', and 'wavy_shape'.\n","    \"\"\"\n","    try:\n","        import math\n","        import numpy as np\n","        import svgwrite\n","        from svgpathtools import svg2paths2\n","        from shapely.geometry import Polygon, Point, LineString\n","        from shapely.ops import unary_union\n","        import matplotlib.pyplot as plt\n","        from matplotlib.patches import Polygon as MplPolygon, Circle as MplCircle, Ellipse as MplEllipse, Rectangle as MplRect\n","    except Exception as e:\n","        raise gr.Error(\n","            f\"Missing dependency for classification step: {e}\\n\"\n","            \"Install: pip install svgpathtools shapely matplotlib svgwrite\"\n","        )\n","\n","    # ---- helpers ----\n","    def sample_points(path, n=360):\n","        return [(float(z.real), float(z.imag)) for z in (path.point(i/(n-1)) for i in range(n))]\n","\n","    def circle_metrics(poly: \"Polygon\"):\n","        centroid = poly.centroid\n","        cx, cy = centroid.x, centroid.y\n","        coords = list(poly.exterior.coords)\n","        if not coords:\n","            return 0.0, 1e9, (cx, cy, 0.0), 1e9\n","        dists = [math.hypot(x-cx, y-cy) for x,y in coords]\n","        r = float(np.mean(dists)) if len(dists) else 0.0\n","        circle = Point(cx,cy).buffer(r, resolution=256)\n","        area_ratio = poly.area / (math.pi*r*r) if r > 0 else 0.0\n","        hd = poly.hausdorff_distance(circle)\n","        rad_std = float(np.std(dists))\n","        return area_ratio, hd, (cx,cy,r), rad_std\n","\n","    def polygon_sides(poly, angle_tol=22, simplify_ratio=0.012):\n","        per = float(poly.length)\n","        tol = max(1.0, simplify_ratio * per)\n","        simp = LineString(list(poly.exterior.coords)).simplify(tol, preserve_topology=False)\n","        coords = list(simp.coords)\n","        if len(coords) < 3: return 0, []\n","        if coords[0] == coords[-1]: coords = coords[:-1]\n","        edges = []\n","        for i in range(len(coords)):\n","            x1,y1 = coords[i]; x2,y2 = coords[(i+1)%len(coords)]\n","            vx, vy = x2-x1, y2-y1\n","            nrm = math.hypot(vx,vy)\n","            if nrm > 1e-6:\n","                edges.append((vx/nrm, vy/nrm))\n","        dirs = []\n","        simp_coords = [coords[0]]\n","        for j,v in enumerate(edges):\n","            ang = math.degrees(math.atan2(v[1], v[0]))\n","            if not dirs:\n","                dirs.append(ang)\n","            else:\n","                prev = dirs[-1]\n","                diff = abs((ang-prev+180)%360 - 180)\n","                if diff > angle_tol:\n","                    dirs.append(ang)\n","                    simp_coords.append(coords[j])\n","        simp_coords.append(coords[-1])\n","        return max(0, len(dirs)), simp_coords\n","\n","    # --- PCA + RANSAC helpers (for arches) ---\n","    def _pca_upright(coords):\n","        P = np.asarray(coords, dtype=float)\n","        C = P.mean(axis=0)\n","        X = P - C\n","        cov = np.cov(X.T)\n","        vals, vecs = np.linalg.eigh(cov)\n","        major = vecs[:, 1]\n","        angle = np.arctan2(major[1], major[0]) - np.pi/2.0\n","        ca, sa = np.cos(-angle), np.sin(-angle)\n","        R = np.array([[ca, -sa], [sa, ca]])\n","        Y = X @ R.T\n","        return Y, angle, C\n","\n","    def _ransac_circle(points: np.ndarray, iters=450, tol=2.5, min_inliers=16):\n","        if len(points) < 6:\n","            return None\n","        best = None\n","        rng = np.random.default_rng(123)\n","        for _ in range(iters):\n","            idx = rng.choice(len(points), size=3, replace=False)\n","            (x1,y1),(x2,y2),(x3,y3) = points[idx]\n","            temp = 2*(x1*(y2 - y3) + x2*(y3 - y1) + x3*(y1 - y2))\n","            if abs(temp) < 1e-6:\n","                continue\n","            ux = ((x1*x1 + y1*y1)*(y2 - y3) + (x2*x2 + y2*y2)*(y3 - y1) + (x3*x3 + y3*y3)*(y1 - y2)) / temp\n","            uy = ((x1*x1 + y1*y1)*(x3 - x2) + (x2*x2 + y2*y2)*(x1 - x3) + (x3*x3 + y3*y3)*(x2 - x1)) / temp\n","            r = np.sqrt((points[:,0]-ux)**2 + (points[:,1]-uy)**2)\n","            R = np.median(r)\n","            dist = np.abs(r - R)\n","            inliers = dist < tol\n","            score = inliers.sum()\n","            if score >= (best[0] if best else -1) and score >= min_inliers:\n","                best = (score, ux, uy, float(R), inliers)\n","        if not best:\n","            return None\n","        _, ux, uy, R, inliers = best\n","        return (ux, uy, R, inliers)\n","\n","    def _ransac_line(points: np.ndarray, iters=300, tol=2.0):\n","        if len(points) < 3:\n","            return None\n","        best = None\n","        rng = np.random.default_rng(321)\n","        for _ in range(iters):\n","            i1 = rng.integers(0, len(points)); i2 = rng.integers(0, len(points))\n","            if i1 == i2:\n","                continue\n","            x1,y1 = points[i1]; x2,y2 = points[i2]\n","            if x2 == x1:\n","                a = 1e9; b = 0.0\n","            else:\n","                a = (y2 - y1) / (x2 - x1)\n","                b = y1 - a*x1\n","            x = points[:,0]; y = points[:,1]\n","            d = np.abs(a*x - y + b) / np.sqrt(a*a + 1.0)\n","            inliers = d < tol\n","            score = inliers.sum()\n","            if (best is None or score > best[0]) and (abs(a) < 0.12):\n","                best = (score, float(a), float(b), inliers)\n","        return None if best is None else (best[1], best[2], best[3])\n","\n","    def _is_arched_shape(coords):\n","        # Need enough points\n","        if not coords or len(coords) < 20:\n","            return False\n","\n","        P = np.asarray(coords, dtype=float)\n","\n","        # Build polygon and basic sanity\n","        poly = Polygon(P).buffer(0)\n","        if (poly.is_empty) or (not poly.is_valid):\n","            return False\n","\n","        # QUICK REJECTION: too rectangle-like?\n","        rect = poly.minimum_rotated_rectangle\n","        area = float(poly.area) if poly.area > 0 else 0.0\n","        rect_area = float(rect.area) if rect.area > 0 else 1.0\n","        rect_area_ratio = area / rect_area\n","        rect_hd = float(poly.hausdorff_distance(rect))\n","        if (rect_area_ratio >= Config.ARCH_RECT_GUARD_AREA_RATIO) and (rect_hd <= Config.ARCH_RECT_GUARD_HD):\n","            return False  # looks very much like a rectangle\n","\n","        # PCA upright as before\n","        Y, angle, center = _pca_upright(coords)\n","        x = Y[:,0]; y = Y[:,1]\n","        xmin, xmax = x.min(), x.max()\n","        ymin, ymax = y.min(), y.max()\n","        w, h = (xmax - xmin), (ymax - ymin)\n","        if w <= 0 or h <= 0:\n","            return False\n","\n","        # Arch should be tall-ish vs width\n","        if h < 0.85 * w:\n","            return False\n","\n","        # If it's nearly a circle, reject (arches aren't round blobs)\n","        cx0, cy0 = Y.mean(axis=0)\n","        R = np.sqrt((Y[:,0]-cx0)**2 + (Y[:,1]-cy0)**2)\n","        if R.std() < 0.06 * max(w, h):\n","            return False\n","\n","        # Split top/bottom bands (slightly tightened)\n","        top_cut = ymin + 0.55*(ymax - ymin)\n","        bot_cut = ymin + 0.82*(ymax - ymin)\n","        top_pts = Y[Y[:,1] <= top_cut]\n","        bot_pts = Y[Y[:,1] >= bot_cut]\n","        if len(top_pts) < 18 or len(bot_pts) < 10:\n","            return False\n","\n","        # Fit a nearly-horizontal base line on bottom points\n","        line = _ransac_line(bot_pts, iters=300, tol=max(1.8, 0.012*max(w,h)))\n","        if line is None:\n","            return False\n","        a,b,inliers_bot = line\n","        inlier_ratio_bot = float(inliers_bot.sum()) / float(len(bot_pts))\n","        y_bottom = np.median(bot_pts[inliers_bot,1]) if inliers_bot.any() else np.median(bot_pts[:,1])\n","\n","        # Base must be flat, near the bottom, and cover most width\n","        if (inlier_ratio_bot < 0.60) or (abs(a) >= 0.12) or ((ymax - y_bottom) > 0.18*h):\n","            return False\n","\n","        # NEW: base coverage across width\n","        base_x = bot_pts[inliers_bot, 0] if inliers_bot.any() else bot_pts[:,0]\n","        if base_x.size >= 2:\n","            base_cov = (base_x.max() - base_x.min()) / max(w, 1e-6)\n","            if base_cov < Config.ARCH_BASE_COVERAGE_MIN:\n","                return False\n","\n","        # Fit a circular arc to the top\n","        circ = _ransac_circle(top_pts, iters=450, tol=max(2.4, 0.018*max(w,h)),\n","                              min_inliers=max(18, int(0.35*len(top_pts))))\n","        if circ is None:\n","            return False\n","        cx, cy, r, inliers_c = circ\n","\n","        # Require a healthy fraction of top points to lie on the arc\n","        inlier_frac_circ = float(inliers_c.sum()) / float(len(top_pts))\n","        if inlier_frac_circ < Config.ARCH_CIRCLE_INLIER_MIN_FRAC:\n","            return False\n","\n","        # Arc span (tightened)\n","        A = top_pts[inliers_c] - np.array([cx, cy])\n","        ang = np.arctan2(A[:,1], A[:,0])\n","        ang = np.unwrap(np.sort(ang))\n","        arc_span = (ang.max() - ang.min())\n","        if arc_span < np.deg2rad(Config.ARCH_MIN_ARC_SPAN_DEG):\n","            return False\n","\n","        # Circle center should be above the arch centroid band (keeps it “cap-like”)\n","        if cy > (ymin + 0.60*h):\n","            return False\n","\n","        # Radius should be plausible relative to width\n","        if not (0.30*w <= r <= 0.85*w):\n","            return False\n","\n","        return True\n","\n","    def _is_circle_adaptive(poly, circularity, ellipse_ar, mec_residual, circ_hd, rad_std, scale):\n","        if scale < Config.SMALL_SHAPE_PX:\n","            circ_ok  = circularity >= Config.CIRCULARITY_MIN_SMALL\n","            ar_ok    = ellipse_ar <= Config.ELLIPSE_AR_MAX_SMALL\n","            std_ok   = rad_std   <= Config.R_STD_FRAC_MAX_SMALL * max(scale, 1.0)\n","            hd_ok    = circ_hd   <= Config.CIRC_HAUSDORFF_MAX_SMALL\n","            mec_ok   = mec_residual <= Config.MEC_RES_FRAC_MAX_SMALL\n","        else:\n","            circ_ok  = circularity >= Config.CIRCULARITY_MIN\n","            ar_ok    = ellipse_ar <= Config.ELLIPSE_AR_MAX\n","            std_ok   = rad_std   <= Config.R_STD_FRAC_MAX * max(scale, 1.0)\n","            hd_ok    = circ_hd   <= Config.CIRC_HAUSDORFF_MAX\n","            mec_ok   = mec_residual <= Config.MEC_RES_FRAC_MAX\n","        return circ_ok and ar_ok and std_ok and hd_ok and mec_ok\n","\n","    def _ellipse_fit_metrics(pts_np):\n","        \"\"\"\n","        Returns (xc, yc, rx, ry, angle_deg, mean_residual_frac) or None\n","        angle in degrees, rx >= ry.\n","        \"\"\"\n","        if len(pts_np) < 5:\n","            return None\n","        try:\n","            (xc, yc), (MA, ma), angle = cv2.fitEllipse(pts_np.astype(np.float32))\n","            # cv2 returns major/minor lengths (diameters)\n","            rx, ry = max(MA, ma)/2.0, min(MA, ma)/2.0\n","            # Residual: distance to ellipse (approx via algebraic distance)\n","            cos_t = np.cos(np.deg2rad(angle)); sin_t = np.sin(np.deg2rad(angle))\n","            X = pts_np[:,0] - xc; Y = pts_np[:,1] - yc\n","            xr =  X*cos_t + Y*sin_t\n","            yr = -X*sin_t + Y*cos_t\n","            # Algebraic residual to unit ellipse\n","            res = np.abs((xr/rx)**2 + (yr/ry)**2 - 1.0)\n","            mean_res = float(np.mean(res))\n","            mean_res_frac = mean_res  # already normalized\n","            return float(xc), float(yc), float(rx), float(ry), float(angle), mean_res_frac\n","        except Exception:\n","            return None\n","\n","    def _is_rectangle(poly, rect_area_ratio, rect_hd):\n","        # Already coarse checks passed in caller. Add near-orthogonal angles:\n","        coords = list(poly.minimum_rotated_rectangle.exterior.coords)\n","        if len(coords) < 4:\n","            return False\n","        # vectors\n","        vecs = []\n","        for i in range(4):\n","            x1,y1 = coords[i]; x2,y2 = coords[(i+1)%4]\n","            vx, vy = x2-x1, y2-y1\n","            n = np.hypot(vx, vy)\n","            if n > 1e-6:\n","                vecs.append((vx/n, vy/n))\n","        if len(vecs) < 2:\n","            return False\n","        dots = []\n","        for i in range(2):\n","            a = np.array(vecs[i]); b = np.array(vecs[(i+1)%4])\n","            dots.append(abs(np.dot(a,b)))\n","        # near 90° => dot ~ 0\n","        return (rect_area_ratio > Config.RECTANGLE_AREA_RATIO) and (rect_hd < Config.RECTANGLE_HD_THRESHOLD) and all(d < np.cos(np.deg2rad(90-Config.RECT_ORTHO_TOL_DEG)) for d in dots)\n","\n","    def _wavy_score(poly):\n","        \"\"\"\n","        Heuristics: count curvature sign changes along simplified contour\n","        + compare perimeter/hull and area/hull.\n","        \"\"\"\n","        coords = np.asarray(list(poly.exterior.coords), dtype=float)\n","        if len(coords) < 20:\n","            return 0, 1.0, 0.0, 0\n","        # curvature via turning angle differences\n","        V = coords[1:] - coords[:-1]\n","        ang = np.unwrap(np.arctan2(V[:,1], V[:,0]))\n","        d_ang = np.diff(ang)\n","        # sign changes\n","        sgn = np.sign(d_ang + 1e-9)\n","        changes = np.sum(np.abs(np.diff(sgn)) > 1e-6)\n","        hull = poly.convex_hull\n","        perim_ratio = float(poly.length) / max(hull.length, 1e-6)\n","        area_ratio = float(poly.area) / max(hull.area, 1e-6)\n","        return changes, perim_ratio, area_ratio, len(coords)\n","\n","    # ---- parse & classify ----\n","    paths, attrs, _ = svg2paths2(svg_file)\n","    results = []\n","\n","    for i,(p,a) in enumerate(zip(paths,attrs)):\n","        pts = sample_points(p, 360)\n","        if pts and pts[0] != pts[-1]:\n","            pts.append(pts[0])\n","        from shapely.geometry import Polygon\n","        poly = Polygon(pts).buffer(0)\n","        if not poly.is_valid or poly.is_empty:\n","            continue\n","\n","        area = float(poly.area)\n","        perim = float(poly.length) if poly.length > 1e-9 else 1e-9\n","        circularity = float(4.0*np.pi*area/(perim*perim))  # 1 for perfect circle\n","\n","        # bounds\n","        minx, miny, maxx, maxy = poly.bounds\n","        W = maxx - minx\n","        H = maxy - miny\n","        scale = max(W, H)\n","\n","        # min enclosing circle residual (OpenCV)\n","        pts_np = np.array(poly.exterior.coords, dtype=np.float32)\n","        (mec_cx, mec_cy), mec_r = cv2.minEnclosingCircle(pts_np)\n","        mec_r = float(mec_r)\n","        if mec_r <= 1e-6:\n","            mec_residual = 1e9\n","        else:\n","            d = np.sqrt((pts_np[:,0]-mec_cx)**2 + (pts_np[:,1]-mec_cy)**2)\n","            mec_residual = float(np.mean(np.abs(d - mec_r))) / mec_r  # normalized\n","\n","        # ellipse fit aspect ratio\n","        ellipse_ar = 9.9\n","        fit_ell = _ellipse_fit_metrics(pts_np)\n","        if fit_ell is not None:\n","            xc, yc, rx, ry, ang_deg, ell_res_frac = fit_ell\n","            if rx > 0 and ry > 0:\n","                big, small = max(rx, ry), min(rx, ry)\n","                ellipse_ar = float(big / small)\n","        else:\n","            xc = yc = rx = ry = ang_deg = ell_res_frac = None\n","\n","        # rectangle fit\n","        rect = poly.minimum_rotated_rectangle\n","        rect_area_ratio = area / float(rect.area) if rect.area > 0 else 0.0\n","        rect_hd = float(poly.hausdorff_distance(rect))\n","        is_rect_coarse = (rect_area_ratio > Config.RECTANGLE_AREA_RATIO) and (rect_hd < Config.RECTANGLE_HD_THRESHOLD)\n","\n","        # circle fit (centroid-based) + Hausdorff + radius std\n","        circ_area_ratio, circ_hd, (cx,cy,r_est), rad_std = (0, 1e9, (0,0,0), 1e9)\n","        try:\n","            circ_area_ratio, circ_hd, (cx,cy,r_est), rad_std = circle_metrics(poly)\n","        except Exception:\n","            pass\n","\n","        # polygon corners\n","        n_sides, simp_coords = polygon_sides(poly, angle_tol=22, simplify_ratio=0.012)\n","\n","        # ---- classification cascade (rectangle before arched_shape) ----\n","        cls = \"unclassified\"\n","        geom = list(poly.exterior.coords)\n","        export_hint = \"path\"\n","\n","        # 1) rectangle (strong rects shouldn't be called arches)\n","        if _is_rectangle(poly, rect_area_ratio, rect_hd):\n","            cls = \"rectangle\"\n","            rect_coords = list(rect.exterior.coords)\n","            xs = [c[0] for c in rect_coords[:-1]]\n","            ys = [c[1] for c in rect_coords[:-1]]\n","            xmin_r, xmax_r = min(xs), max(xs)\n","            ymin_r, ymax_r = min(ys), max(ys)\n","            v = np.array(rect_coords[1]) - np.array(rect_coords[0])\n","            ang = np.degrees(np.arctan2(v[1], v[0]))\n","            axis_aligned = (abs((ang+360)%90) < 2.0) or (abs((ang)%90) < 2.0)\n","            if axis_aligned:\n","                geom = {\"x\": round(float(xmin_r),2), \"y\": round(float(ymin_r),2),\n","                        \"width\": round(float(xmax_r-xmin_r),2), \"height\": round(float(ymax_r-ymin_r),2)}\n","                export_hint = \"rect\"\n","            else:\n","                geom = rect_coords\n","                export_hint = \"path\"\n","\n","        else:\n","            # 2) arched shape (now after rectangle)\n","            if _is_arched_shape(list(poly.exterior.coords)):\n","                cls = \"arched_shape\"\n","                geom = list(poly.exterior.coords)\n","                export_hint = \"path\"\n","\n","            else:\n","                # 3) circle\n","                is_round_enough = _is_circle_adaptive(poly, circularity, ellipse_ar, mec_residual, circ_hd, rad_std, scale)\n","                if is_round_enough:\n","                    cls = \"circle\"\n","                    ccx, ccy, rr = (cx if r_est > 0 else mec_cx,\n","                                    cy if r_est > 0 else mec_cy,\n","                                    r_est if r_est > 0 else mec_r)\n","                    geom = {\"center\": [round(float(ccx), 2), round(float(ccy), 2)],\n","                            \"radius\": round(float(rr), 2)}\n","                    export_hint = \"circle\"\n","                else:\n","                    # 4) ellipse (non-circular)\n","                    if fit_ell is not None:\n","                        ar_ok = (ellipse_ar >= Config.ELLIPSE_MIN_AR) and (ellipse_ar <= Config.ELLIPSE_MAX_AR)\n","                        res_ok = (ell_res_frac <= Config.ELLIPSE_RESIDUAL_FRAC_MAX)\n","                        if ar_ok and res_ok:\n","                            cls = \"ellipse\"\n","                            geom = {\n","                                \"center\": [round(float(xc),2), round(float(yc),2)],\n","                                \"rx\": round(float(rx),2),\n","                                \"ry\": round(float(ry),2),\n","                                \"angle_deg\": round(float(ang_deg),2)\n","                            }\n","                            export_hint = \"ellipse\"\n","\n","                    if cls == \"unclassified\":\n","                        # 5) polygon (named if 3..12)\n","                        names = {3:\"triangle\",4:\"quadrilateral\",5:\"pentagon\",6:\"hexagon\",\n","                                 7:\"heptagon\",8:\"octagon\",9:\"nonagon\",10:\"decagon\",\n","                                 11:\"hendecagon\",12:\"dodecagon\"}\n","                        if n_sides >= 3:\n","                            cls = names.get(n_sides, f\"polygon_{n_sides}_sides\")\n","                            geom = simp_coords if len(simp_coords) >= 3 else list(poly.exterior.coords)\n","                            export_hint = \"path\"\n","                        else:\n","                            # 6) wavy shape: many inflections and rich/hull ratios\n","                            changes, perim_ratio, area_ratio, npts = _wavy_score(poly)\n","                            if (changes >= Config.WAVY_MIN_INFLECTIONS and\n","                                perim_ratio >= Config.WAVY_PERIM_TO_HULL_MIN and\n","                                area_ratio >= Config.WAVY_AREA_HULL_RATIO_MIN):\n","                                cls = \"wavy_shape\"\n","                                geom = list(poly.exterior.coords)\n","                                export_hint = \"path\"\n","                            else:\n","                                cls = \"unclassified\"\n","                                geom = list(poly.exterior.coords)\n","                                export_hint = \"path\"\n","\n","        results.append({\n","            \"id\": a.get(\"id\", f\"elem_{i}\"),\n","            \"classification\": cls,\n","            \"export_hint\": export_hint,\n","            \"n_sides\": int(n_sides),\n","            \"circularity\": round(circularity,4),\n","            \"ellipse_ar\": round(float(ellipse_ar),4) if np.isfinite(ellipse_ar) else None,\n","            \"ellipse_residual_frac\": round(float(ell_res_frac),4) if fit_ell is not None else None,\n","            \"mec_residual\": round(float(mec_residual),4),\n","            \"rect_area_ratio\": round(rect_area_ratio,3),\n","            \"rect_hd\": round(rect_hd,2),\n","            \"circ_area_ratio\": round(float(circ_area_ratio),3),\n","            \"circ_hd\": round(float(circ_hd),2),\n","            \"radius_std\": round(float(rad_std),3),\n","            \"geometry\": geom\n","        })\n","\n","    # Save JSON\n","    base, _ = os.path.splitext(svg_file)\n","    json_file = base + \"_classified.json\"\n","    with open(json_file, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(results, f, indent=2)\n","\n","    # Labeled JPG preview\n","    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f)\n","\n","    all_x, all_y = [], []\n","    for shape in data:\n","        geom = shape[\"geometry\"]\n","        if isinstance(geom, dict):\n","            if \"radius\" in geom:  # circle\n","                cx, cy = geom[\"center\"]; r = geom[\"radius\"]\n","                all_x += [cx-r, cx+r]; all_y += [cy-r, cy+r]\n","            elif \"rx\" in geom and \"ry\" in geom:  # ellipse\n","                cx, cy = geom[\"center\"]; rx, ry = geom[\"rx\"], geom[\"ry\"]\n","                all_x += [cx-rx, cx+rx]; all_y += [cy-ry, cy+ry]\n","            elif {\"x\",\"y\",\"width\",\"height\"} <= set(geom.keys()):\n","                all_x += [geom[\"x\"], geom[\"x\"]+geom[\"width\"]]\n","                all_y += [geom[\"y\"], geom[\"y\"]+geom[\"height\"]]\n","        elif isinstance(geom, list) and geom:\n","            try:\n","                xs, ys = zip(*geom)\n","                all_x += xs; all_y += ys\n","            except Exception:\n","                pass\n","    if not all_x or not all_y:\n","        xmin, xmax, ymin, ymax = 0, 100, 0, 100\n","    else:\n","        xmin, xmax = min(all_x), max(all_x)\n","        ymin, ymax = min(all_y), max(all_y)\n","    if xmax == xmin: xmax += 1\n","    if ymax == ymin: ymax += 1\n","\n","    import matplotlib.pyplot as plt\n","    from matplotlib.patches import Polygon as MplPolygon, Circle as MplCircle, Ellipse as MplEllipse, Rectangle as MplRect\n","\n","    fig1, ax1 = plt.subplots(figsize=(10, 10))\n","    ax1.set_aspect(\"equal\")\n","    ax1.invert_yaxis()\n","    for shape in data:\n","        cls = shape[\"classification\"]; geom = shape[\"geometry\"]\n","        try:\n","            if cls == \"circle\" and isinstance(geom, dict):\n","                cx, cy = geom[\"center\"]; r = geom[\"radius\"]\n","                circ = MplCircle((cx, cy), r, fill=True, facecolor=\"#000\",\n","                                 edgecolor=\"#000\", alpha=0.35, linewidth=1.2)\n","                ax1.add_patch(circ)\n","                ax1.text(cx, cy, cls, color='grey', ha=\"center\", va=\"center\", fontsize=8, fontweight='bold')\n","            elif cls == \"ellipse\" and isinstance(geom, dict):\n","                cx, cy = geom[\"center\"]; rx, ry = geom[\"rx\"], geom[\"ry\"]; ang = geom[\"angle_deg\"]\n","                ell = MplEllipse((cx, cy), 2*rx, 2*ry, angle=ang, fill=True, facecolor=\"#000\",\n","                                 edgecolor=\"#000\", alpha=0.35, linewidth=1.2)\n","                ax1.add_patch(ell)\n","                ax1.text(cx, cy, cls, color='grey', ha=\"center\", va=\"center\", fontsize=8, fontweight='bold')\n","            elif cls == \"rectangle\" and isinstance(geom, dict) and {\"x\",\"y\",\"width\",\"height\"} <= set(geom.keys()):\n","                rect = MplRect((geom[\"x\"], geom[\"y\"]), geom[\"width\"], geom[\"height\"],\n","                               fill=True, facecolor=\"#000\", edgecolor=\"#000\", alpha=0.85, linewidth=1.0)\n","                ax1.add_patch(rect)\n","                cx = geom[\"x\"] + geom[\"width\"]/2; cy = geom[\"y\"] + geom[\"height\"]/2\n","                ax1.text(cx, cy, cls, color='grey', ha=\"center\", va=\"center\", fontsize=8, fontweight='bold')\n","            elif isinstance(geom, list) and len(geom) > 2:\n","                poly = MplPolygon(geom, fill=True, facecolor=\"#000\",\n","                                  edgecolor=\"#000\", alpha=0.85, linewidth=1.0)\n","                ax1.add_patch(poly)\n","                xs, ys = zip(*geom)\n","                cx = sum(xs)/len(xs); cy = sum(ys)/len(ys)\n","                ax1.text(cx, cy, cls, color='grey', ha=\"center\", va=\"center\", fontsize=8, fontweight='bold')\n","        except Exception:\n","            continue\n","    ax1.set_xlim(xmin, xmax)\n","    ax1.set_ylim(ymax, ymin)\n","    ax1.axis(\"off\")\n","    jpg_path = os.path.join(out_dir, \"classified_output.jpg\")\n","    plt.savefig(jpg_path, dpi=150, bbox_inches=\"tight\", facecolor='white', edgecolor='none')\n","    plt.close(fig1)\n","\n","    # Clean, typed SVG with valid attributes\n","    import svgwrite\n","    dwg = svgwrite.Drawing(size=(xmax - xmin, ymax - ymin))\n","    dwg.viewbox(minx=xmin, miny=ymin, width=(xmax - xmin), height=(ymax - ymin))\n","    try:\n","        legend = {sh[\"id\"]: sh[\"classification\"] for sh in data}\n","        dwg.add(dwg.metadata(json.dumps({\"classes\": legend}, ensure_ascii=False)))\n","    except Exception:\n","        pass\n","\n","    def _add_path(points, _id, cls):\n","        pts = [(float(x), float(y)) for x,y in points]\n","        d = \"M \" + \" L \".join(f\"{x},{y}\" for x,y in pts) + \" Z\"\n","        el = dwg.path(d=d, fill='black', stroke='black', **{\"stroke-width\":1.5})\n","        if _id: el[\"id\"] = _id\n","        el[\"class\"] = cls\n","        el.set_desc(title=cls)\n","        dwg.add(el)\n","\n","    for shape in data:\n","        cls = shape[\"classification\"]\n","        geom = shape[\"geometry\"]\n","        elem_id = shape.get(\"id\", \"\")\n","        hint = shape.get(\"export_hint\", \"path\")\n","\n","        try:\n","            if hint == \"circle\" and isinstance(geom, dict):\n","                cx, cy = geom[\"center\"]; r = geom[\"radius\"]\n","                el = dwg.circle(center=(cx, cy), r=r, fill='black', stroke='black', **{\"stroke-width\":1.5})\n","                if elem_id: el[\"id\"] = elem_id\n","                el[\"class\"] = cls\n","                el.set_desc(title=cls)\n","                dwg.add(el)\n","            elif hint == \"ellipse\" and isinstance(geom, dict):\n","                cx, cy = geom[\"center\"]; rx, ry = geom[\"rx\"], geom[\"ry\"]; ang = geom[\"angle_deg\"]\n","                el = dwg.ellipse(center=(cx, cy), r=(rx, ry), fill='black', stroke='black', **{\"stroke-width\":1.5})\n","                # rotation about center\n","                el.rotate(ang, center=(cx, cy))\n","                if elem_id: el[\"id\"] = elem_id\n","                el[\"class\"] = cls\n","                el.set_desc(title=cls)\n","                dwg.add(el)\n","            elif hint == \"rect\" and isinstance(geom, dict) and {\"x\",\"y\",\"width\",\"height\"} <= set(geom.keys()):\n","                el = dwg.rect(insert=(geom[\"x\"], geom[\"y\"]), size=(geom[\"width\"], geom[\"height\"]),\n","                              fill='black', stroke='black', **{\"stroke-width\":1.5})\n","                if elem_id: el[\"id\"] = elem_id\n","                el[\"class\"] = cls\n","                el.set_desc(title=cls)\n","                dwg.add(el)\n","            elif isinstance(geom, list) and len(geom) > 2:\n","                _add_path(geom, elem_id, cls)\n","        except Exception:\n","            # Fallback: path\n","            if isinstance(geom, list) and len(geom) > 2:\n","                _add_path(geom, elem_id, cls)\n","\n","    svg_out_path = os.path.join(out_dir, \"classified_output.svg\")\n","    dwg.saveas(svg_out_path)\n","\n","    return jpg_path, svg_out_path\n","\n","\n","# -----------------------------------------------------------------------------\n","# Inference function\n","# -----------------------------------------------------------------------------\n","def run_inference(\n","    image: np.ndarray,\n","    prompt_text: str,\n","    box_threshold: float,\n","    text_threshold: float,\n","    conf_threshold: float,\n","    max_inclusions: int,\n","    reinit_model: bool,\n","):\n","    try:\n","        import supervision as sv\n","    except Exception as e:\n","        raise gr.Error(f\"Missing dependency 'supervision': {e}\")\n","    try:\n","        from autodistill.detection import CaptionOntology\n","        from autodistill_grounded_sam_2 import GroundedSAM2\n","    except Exception as e:\n","        raise gr.Error(f\"Autodistill / GroundedSAM2 not installed or import failed: {e}\")\n","\n","    if image is None:\n","        raise gr.Error(\"Please upload an image.\")\n","\n","    # Auto-reinit model when prompt (ontology) changes\n","    global base_model, LAST_ONTOLOGY_SIG\n","    onto_dict = _parse_prompt_to_ontology_dict(prompt_text) or {\"window\": \"window\"}\n","    onto_sig = \"|\".join(f\"{k}=>{v}\" for k, v in sorted(onto_dict.items()))\n","    need_init = reinit_model or base_model is None or LAST_ONTOLOGY_SIG != onto_sig\n","    if need_init:\n","        try:\n","            base_model = GroundedSAM2(\n","                ontology=CaptionOntology(onto_dict),\n","                model=\"Grounding DINO\",\n","                grounding_dino_box_threshold=float(box_threshold),\n","                grounding_dino_text_threshold=float(text_threshold),\n","            )\n","            LAST_ONTOLOGY_SIG = onto_sig\n","            logger.info(f\"Initialized model with ontology: {onto_dict}\")\n","        except Exception as e:\n","            raise gr.Error(f\"Failed to initialize GroundedSAM2: {e}\")\n","\n","    # Persist inputs\n","    bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","    tmp_root = _ensure_dir(os.path.join(tempfile.gettempdir(), \"gsam2_gradio\"))\n","    stamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n","    out_dir = _ensure_dir(os.path.join(tmp_root, f\"out_{stamp}\"))\n","    img_path = os.path.join(out_dir, f\"input_{stamp}.jpg\")\n","    cv2.imwrite(img_path, bgr)\n","\n","    # Predict\n","    results = base_model.predict(img_path)\n","    if hasattr(results, \"with_nms\"):\n","        try:\n","            results = results.with_nms()\n","        except Exception:\n","            pass\n","\n","    # Confidence filter\n","    try:\n","        det_conf = np.array(getattr(results, \"confidence\", []))\n","        if det_conf.size:\n","            keep = det_conf > float(conf_threshold)\n","            results = results[keep]\n","    except Exception:\n","        pass\n","\n","    # Labels for overlay\n","    labels = []\n","    names = getattr(results, \"class_names\", None) or getattr(results, \"class_name\", None)\n","    confidences = _to_list(getattr(results, \"confidence\", None))\n","    if names is not None and len(_to_list(names)):\n","        for name, conf in zip(_to_list(names), confidences):\n","            try:\n","                conf_f = float(conf)\n","            except Exception:\n","                conf_f = 0.0\n","            labels.append(f\"{str(name)} {conf_f:.2f}\")\n","    else:\n","        class_ids = _to_list(getattr(results, \"class_id\", None))\n","        onto_labels = list(onto_dict.values())\n","        for cid, conf in zip(class_ids, confidences):\n","            try:\n","                name = onto_labels[int(cid)]\n","            except Exception:\n","                name = str(cid)\n","            try:\n","                conf_f = float(conf)\n","            except Exception:\n","                conf_f = 0.0\n","            labels.append(f\"{name} {conf_f:.2f}\")\n","\n","    # Annotated image\n","    image_bgr = bgr.copy()\n","    try:\n","        import supervision as sv\n","        box_annotator = sv.BoxAnnotator()\n","        label_annotator = sv.LabelAnnotator()\n","        annotated_bgr = box_annotator.annotate(image_bgr, detections=results)\n","        annotated_bgr = label_annotator.annotate(scene=annotated_bgr, detections=results, labels=labels)\n","    except Exception:\n","        annotated_bgr = image_bgr\n","\n","    # Combined mask\n","    H, W = image.shape[:2]\n","    combined_mask = np.zeros((H, W), dtype=np.uint8)\n","    try:\n","        bdbs = get_bounding_boxes(results)\n","        inclusion_mask = create_inclusion_mask(bdbs, max_inclusions=max_inclusions)\n","        try:\n","            mask_bool = np.array(inclusion_mask) == False\n","            filtered = results[mask_bool]\n","        except Exception:\n","            filtered = results\n","\n","        masks = getattr(filtered, \"mask\", None)\n","        if masks is None:\n","            masks = getattr(filtered, \"masks\", None)\n","        if masks is not None and len(masks) > 0:\n","            m = np.zeros_like(masks[0], dtype=np.uint8)\n","            for mk in masks:\n","                m = np.maximum(m, mk.astype(np.uint8))\n","            combined_mask = (m > 0).astype(np.uint8) * 255\n","    except Exception:\n","        try:\n","            masks = getattr(results, \"mask\", None)\n","            if masks is None:\n","                masks = getattr(results, \"masks\", None)\n","            if masks is not None and len(masks) > 0:\n","                m = np.zeros_like(masks[0], dtype=np.uint8)\n","                for mk in masks:\n","                    m = np.maximum(m, mk.astype(np.uint8))\n","                combined_mask = (m > 0).astype(np.uint8) * 255\n","        except Exception:\n","            pass\n","\n","    # Detections table\n","    rows = []\n","    try:\n","        xyxy = np.array(getattr(results, \"xyxy\", []))\n","        confs = _to_list(getattr(results, \"confidence\", None))\n","        names_attr = getattr(results, \"class_names\", None) or getattr(results, \"class_name\", None)\n","        names_list = _to_list(names_attr)\n","        onto_labels = list(onto_dict.values())\n","        default_label = onto_labels[0] if onto_labels else \"object\"\n","\n","        label_names = []\n","        if names_list and len(names_list) == (xyxy.shape[0] if xyxy.ndim == 2 else len(names_list)):\n","            label_names = [str(n) if n is not None else default_label for n in names_list]\n","        else:\n","            cids = _to_list(getattr(results, \"class_id\", None))\n","            num_dets = xyxy.shape[0] if (xyxy.ndim == 2 and xyxy.shape[1] >= 4) else len(cids)\n","            for i in range(num_dets):\n","                name = default_label\n","                if i < len(cids):\n","                    cid = cids[i]\n","                    try:\n","                        cid_int = int(cid)\n","                        if 0 <= cid_int < len(onto_labels):\n","                            name = onto_labels[cid_int]\n","                        else:\n","                            name = str(cid)\n","                    except Exception:\n","                        name = str(cid) if cid is not None else default_label\n","                label_names.append(str(name))\n","\n","        if xyxy.ndim == 2 and xyxy.shape[1] >= 4:\n","            for i, bb in enumerate(xyxy):\n","                x1, y1, x2, y2 = [int(v) for v in bb[:4]]\n","                cf = float(confs[i]) if (confs and i < len(confs)) else None\n","                label = label_names[i] if i < len(label_names) else default_label\n","                rows.append(\n","                    {\"instance_label\": None, \"label\": label, \"confidence\": cf, \"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2}\n","                )\n","        df = pd.DataFrame(rows)\n","    except Exception:\n","        df = pd.DataFrame(columns=[\"instance_label\", \"label\", \"confidence\", \"x1\", \"y1\", \"x2\", \"y2\"])\n","\n","    # Add instance labels\n","    try:\n","        if not df.empty:\n","            df[\"label\"] = df[\"label\"].astype(str)\n","            missing_mask = df[\"label\"].isin([None, \"\", \"nan\", \"None\"])\n","            onto_labels = list(onto_dict.values())\n","            default_label = onto_labels[0] if onto_labels else \"object\"\n","            df.loc[missing_mask, \"label\"] = default_label\n","\n","            base = (\n","                df[\"label\"]\n","                .str.lower()\n","                .str.replace(r\"[^a-z0-9_-]+\", \"_\", regex=True)\n","                .str.strip(\"_\")\n","            )\n","            df[\"__class_norm__\"] = base.where(base.ne(\"\"), default_label)\n","            df[\"__idx__\"] = df.groupby(\"__class_norm__\").cumcount() + 1\n","            df[\"instance_label\"] = df[\"__class_norm__\"] + \"_\" + df[\"__idx__\"].astype(str)\n","            df = df[[\"instance_label\", \"label\", \"confidence\", \"x1\", \"y1\", \"x2\", \"y2\"]]\n","    except Exception:\n","        pass\n","\n","    # Save artifacts\n","    ann_path = os.path.join(out_dir, \"annotated.jpg\")\n","    mask_path = os.path.join(out_dir, \"combined_mask.png\")\n","    csv_path = os.path.join(out_dir, \"detections.csv\")\n","    cv2.imwrite(ann_path, annotated_bgr)\n","    cv2.imwrite(mask_path, combined_mask)\n","    df.to_csv(csv_path, index=False)\n","\n","    # SVG from mask\n","    try:\n","        svg_string = _mask_to_svg_string(combined_mask.astype(np.uint8))\n","    except Exception:\n","        h, w = combined_mask.shape[:2]\n","        svg_string = f'<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"{w}\" height=\"{h}\" viewBox=\"0 0 {w} {h}\"></svg>'\n","\n","    svg_path = os.path.join(out_dir, \"mask_output.svg\")\n","    with open(svg_path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(svg_string)\n","\n","    # Classification assets\n","    classified_jpg, classified_svg = _classify_svg_assets(svg_path, out_dir)\n","\n","    # ZIP\n","    zip_path = os.path.join(os.path.dirname(out_dir), f\"gsam2_outputs_{os.path.basename(out_dir)}.zip\")\n","    base, _ = os.path.splitext(svg_path)\n","    json_path = base + \"_classified.json\"\n","    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n","        for p in (ann_path, mask_path, csv_path, svg_path, json_path, classified_jpg, classified_svg):\n","            if os.path.isfile(p):\n","                zf.write(p, arcname=os.path.basename(p))\n","\n","    annotated_rgb = cv2.cvtColor(annotated_bgr, cv2.COLOR_BGR2RGB)\n","    classified_rgb = cv2.cvtColor(cv2.imread(classified_jpg), cv2.COLOR_BGR2RGB)\n","\n","    return annotated_rgb, combined_mask, df, svg_path, zip_path, classified_rgb, classified_svg\n","\n","\n","# -----------------------------------------------------------------------------\n","# Gradio UI\n","# -----------------------------------------------------------------------------\n","with gr.Blocks(title=Config.APP_TITLE) as demo:\n","    gr.Markdown(Config.APP_DESC)\n","\n","    with gr.Row():\n","        with gr.Column():\n","            inp_image = gr.Image(label=\"Upload facade image\", type=\"numpy\")\n","            prompt = gr.Textbox(\n","                label=\"Objects to detect\",\n","                placeholder=\"e.g., window or window, door\",\n","                value=\"window\",\n","            )\n","            gr.Examples([\"window\", \"window, door\", \"window, door, balcony\"], prompt)\n","\n","            with gr.Accordion(\"Advanced thresholds\", open=True):\n","                box_thr = gr.Slider(0.0, 1.0, value=Config.DEFAULT_BOX_THRESHOLD, step=0.01,\n","                                    label=\"GroundingDINO box threshold\")\n","                text_thr = gr.Slider(0.0, 1.0, value=Config.DEFAULT_TEXT_THRESHOLD, step=0.01,\n","                                     label=\"GroundingDINO text threshold\")\n","                conf_thr = gr.Slider(0.0, 1.0, value=Config.DEFAULT_CONF_THRESHOLD, step=0.01,\n","                                     label=\"Post-NMS detection confidence filter\")\n","                max_incl = gr.Slider(0, 10, value=Config.DEFAULT_MAX_INCLUSIONS, step=1,\n","                                     label=\"Max inclusions (filter big enclosing boxes)\")\n","            reinit_ck = gr.Checkbox(value=False, label=\"Re-initialize model from prompt (optional)\")\n","            run_btn = gr.Button(\"Run segmentation\", variant=\"primary\")\n","\n","        with gr.Column():\n","            out_ann = gr.Image(label=\"Annotated image\", type=\"numpy\")\n","            out_df = gr.Dataframe(label=\"Detections\", interactive=False)\n","            out_zip = gr.File(label=\"Download outputs (zip)\")\n","\n","    with gr.Row(equal_height=True):\n","        out_mask = gr.Image(label=\"Combined mask (0/255)\", type=\"numpy\")\n","        out_classified = gr.Image(label=\"Cleaned & Classified Output (from SVG)\", type=\"numpy\")\n","\n","    with gr.Row(equal_height=True):\n","        out_svg_btn = gr.DownloadButton(label=\"⬇️ Download mask as SVG\")\n","        out_classified_svg_btn = gr.DownloadButton(label=\"⬇️ Download Cleaned & Classified SVG\")\n","\n","    run_btn.click(\n","        fn=run_inference,\n","        inputs=[inp_image, prompt, box_thr, text_thr, conf_thr, max_incl, reinit_ck],\n","        outputs=[out_ann, out_mask, out_df, out_svg_btn, out_zip, out_classified, out_classified_svg_btn],\n","        api_name=\"segment\"\n","    )\n","\n","# You may set share=True if you want a public link\n","# demo.launch(quiet=True, debug=True, prevent_thread_lock=True)\n","demo.launch(quiet=True, debug=True, prevent_thread_lock=True)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[{"file_id":"1qNYFPD1P5En1W8mI0r7D1Eu-YFCcEcka","timestamp":1752878539751}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}